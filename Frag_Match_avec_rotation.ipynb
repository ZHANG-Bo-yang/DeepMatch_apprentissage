{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from PIL import Image\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_imshow(im_tensor,cannel):\n",
    "    b,c,h,w=im_tensor.shape\n",
    "    if c==1:\n",
    "        plt.imshow(im_tensor.squeeze().detach().numpy())\n",
    "    else:\n",
    "        plt.imshow(im_tensor.squeeze().detach().numpy()[cannel,:])\n",
    "        \n",
    "def get_training_fragment(frag_size,im):\n",
    "    h,w,c=im.shape\n",
    "    n=random.randint(0,int(h/frag_size)-1)\n",
    "    m=random.randint(0,int(w/frag_size)-1)\n",
    "    \n",
    "    shape=frag_size/4\n",
    "    vt_h=math.ceil((h+1)/shape)\n",
    "    vt_w=math.ceil((w+1)/shape)\n",
    "    vt=np.zeros([vt_h,vt_w])\n",
    "    vt_h_po=round((vt_h-1)*(n*frag_size/(h-1)+(n+1)*frag_size/(h-1))/2)\n",
    "    vt_w_po=round((vt_w-1)*(m*frag_size/(w-1)+(m+1)*frag_size/(w-1))/2)\n",
    "    vt[vt_h_po,vt_w_po]=1\n",
    "    vt = np.float32(vt)\n",
    "    vt=torch.from_numpy(vt.reshape(1,1,vt_h,vt_w))\n",
    "    \n",
    "    return im[n*frag_size:(n+1)*frag_size,m*frag_size:(m+1)*frag_size,:],vt\n",
    "\"\"\"\n",
    "def get_training_fragment(frag_size,im):\n",
    "    h,w,c=im.shape\n",
    "    n=random.randint(0,int(h-frag_size-1))\n",
    "    m=random.randint(0,int(w-frag_size-1))\n",
    "    \n",
    "    vt_h=math.ceil((h+1)/8)\n",
    "    vt_w=math.ceil((w+1)/8)\n",
    "    vt=np.zeros([vt_h,vt_w])\n",
    "    vt_h_po=round((vt_h-1)*(2*n+frag_size)/(2*(h-1)))\n",
    "    vt_w_po=round((vt_w-1)*(2*m+frag_size)/(2*(w-1)))\n",
    "    vt[vt_h_po,vt_w_po]=1\n",
    "    vt = np.float32(vt)\n",
    "    vt=torch.from_numpy(vt.reshape(1,1,vt_h,vt_w))\n",
    "    \n",
    "    return im[n:n+frag_size,m:m+frag_size,:],vt\n",
    "\"\"\"\n",
    "def img2tensor(im):\n",
    "    im=np.array(im,dtype=\"float32\")\n",
    "    tensor_cv = torch.from_numpy(np.transpose(im, (2, 0, 1)))\n",
    "    im_tensor=tensor_cv.unsqueeze(0)\n",
    "    return im_tensor\n",
    "\n",
    "def show_coordonnee(position_pred):\n",
    "    map_corre=position_pred.squeeze().detach().numpy()\n",
    "    score=sum(sum(map_corre))\n",
    "    h,w=map_corre.shape\n",
    "    max_value=map_corre.max()\n",
    "    coordonnee=np.where(map_corre==max_value)\n",
    "    return score,coordonnee[0].mean()/h,coordonnee[1].mean()/w\n",
    "    \"\"\"\n",
    "    if len(coordonnee[0])==1:\n",
    "        h_=coordonnee[0][0]/h\n",
    "        w_=coordonnee[1][0]/w\n",
    "        return max_value,h_,w_\n",
    "    else:\n",
    "        return -1,-1,-1\n",
    "    \"\"\"\n",
    "\n",
    "def test_fragment32_32(frag,seuillage):\n",
    "    a=frag[:,:,0]+frag[:,:,1]+frag[:,:,2]\n",
    "    mask = (a == 0)\n",
    "    arr_new = a[mask]\n",
    "    if arr_new.size/a.size<=(1-seuillage):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def save_net(file_path,net):\n",
    "    pkl_file = open(file_path, 'wb')\n",
    "    pickle.dump(net,pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "def load_net(file_path):   \n",
    "    pkl_file = open(file_path, 'rb')\n",
    "    net= pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_add_ini(n,m):\n",
    "    input_canal=int(n*m)\n",
    "    output_canal=int(n/2)*int(m/2)\n",
    "    for i in range(int(n/2)):\n",
    "        for j in range(int(m/2)):\n",
    "            kernel_add=np.zeros([1,input_canal],dtype='float32')\n",
    "            kernel_add[0,i*2*m+j*2]=1\n",
    "            kernel_add[0,i*2*m+j*2+1]=1\n",
    "            kernel_add[0,(i*2+1)*m+j*2]=1\n",
    "            kernel_add[0,(i*2+1)*m+j*2+1]=1\n",
    "            if i==0 and j==0:\n",
    "                add=torch.from_numpy(kernel_add.reshape(1,input_canal,1,1))\n",
    "            else:\n",
    "                add_=torch.from_numpy(kernel_add.reshape(1,input_canal,1,1))\n",
    "                add=torch.cat((add,add_),0)\n",
    "    return torch.nn.Parameter(add,requires_grad=False) \n",
    "\n",
    "def kernel_shift_ini(n,m):\n",
    "    input_canal=int(n*m)\n",
    "    output_canal=int(n*m)\n",
    "    \n",
    "    kernel_shift=torch.zeros([output_canal,input_canal,3,3])\n",
    "    \n",
    "    array_0=np.array([[1,0,0],[0,0,0],[0,0,0]],dtype='float32')\n",
    "    array_1=np.array([[0,0,1],[0,0,0],[0,0,0]],dtype='float32')\n",
    "    array_2=np.array([[0,0,0],[0,0,0],[1,0,0]],dtype='float32')\n",
    "    array_3=np.array([[0,0,0],[0,0,0],[0,0,1]],dtype='float32')\n",
    "    \n",
    "    kernel_shift_0=torch.from_numpy(array_0)\n",
    "    kernel_shift_1=torch.from_numpy(array_1)\n",
    "    kernel_shift_2=torch.from_numpy(array_2)\n",
    "    kernel_shift_3=torch.from_numpy(array_3)\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if i==0 and j==0:\n",
    "                kernel_shift[0,0,:]=kernel_shift_0\n",
    "            else:\n",
    "                if i%2==0 and j%2==0:\n",
    "                    kernel_shift[i*m+j,i*m+j,:]=kernel_shift_0\n",
    "                if i%2==0 and j%2==1:\n",
    "                    kernel_shift[i*m+j,i*m+j,:]=kernel_shift_1\n",
    "                if i%2==1 and j%2==0:\n",
    "                    kernel_shift[i*m+j,i*m+j,:]=kernel_shift_2\n",
    "                if i%2==1 and j%2==1:\n",
    "                    kernel_shift[i*m+j,i*m+j,:]=kernel_shift_3\n",
    "                    \n",
    "    return torch.nn.Parameter(kernel_shift,requires_grad=False) \n",
    "\n",
    "def get_patch(fragment,psize,n,m):\n",
    "    return fragment[:,:,n*psize:(n+1)*psize,m*psize:(m+1)*psize]\n",
    "\n",
    "def shift_1pixel(map_corr,num_patch):\n",
    "    #num_patch:\n",
    "    #          0 1\n",
    "    #          2 3\n",
    "    h,w=map_corr.shape\n",
    "    map_shifted=torch.zeros([h,w])\n",
    "    if num_patch==0:\n",
    "        map_shifted[1:h,1:w]=map_corr[0:h-1,0:w-1]\n",
    "    if num_patch==1:\n",
    "        map_shifted[1:h,0:w-1]=map_corr[0:h-1,1:w]\n",
    "    if num_patch==2:\n",
    "        map_shifted[0:h-1,1:w]=map_corr[1:h,0:w-1]\n",
    "    if num_patch==3:\n",
    "        map_shifted[0:h-1,0:w-1]=map_corr[1:h,1:w]\n",
    "        \n",
    "    return map_shifted\n",
    "\n",
    "def shift_map_corre(n,m,map_corre):\n",
    "    b,c,h,w=map_corre.shape\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if i%2==0 and j%2==0:\n",
    "                map_corre[0,i*m+j,:,:]=shift_1pixel(map_corre[0,i*m+j,:,:],0)\n",
    "            if i%2==0 and j%2==1:\n",
    "                map_corre[0,i*m+j,:,:]=shift_1pixel(map_corre[0,i*m+j,:,:],1)\n",
    "            if i%2==1 and j%2==0:\n",
    "                map_corre[0,i*m+j,:,:]=shift_1pixel(map_corre[0,i*m+j,:,:],2)\n",
    "            if i%2==1 and j%2==1:\n",
    "                map_corre[0,i*m+j,:,:]=shift_1pixel(map_corre[0,i*m+j,:,:],3)\n",
    "    return map_corre\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,frag_size,psize):\n",
    "        super(Net, self).__init__()\n",
    "       \n",
    "        h_fr=frag_size\n",
    "        w_fr=frag_size\n",
    "        \n",
    "        n=int(h_fr/psize) #n*m patches\n",
    "        m=int(w_fr/psize)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,8,kernel_size=3,stride=1,padding=1)\n",
    "        #self.conv1.weight=ini()\n",
    "        self.Relu = nn.ReLU(inplace=True)\n",
    "        self.maxpooling=nn.MaxPool2d(3,stride=2, padding=1)\n",
    "        \n",
    "        self.shift1=nn.Conv2d(n*m,n*m,kernel_size=3,stride=1,padding=1)\n",
    "        self.shift1.weight=kernel_shift_ini(n,m)\n",
    "        self.add1 = nn.Conv2d(n*m,int(n/2)*int(m/2),kernel_size=1,stride=1,padding=0)\n",
    "        self.add1.weight=kernel_add_ini(n,m)\n",
    "        \n",
    "        n=int(n/2)\n",
    "        m=int(m/2)\n",
    "        if n>=2 and m>=2:\n",
    "            self.shift2=nn.Conv2d(n*m,n*m,kernel_size=3,stride=1,padding=1)\n",
    "            self.shift2.weight=kernel_shift_ini(n,m)\n",
    "            self.add2 = nn.Conv2d(n*m,int(n/2)*int(m/2),kernel_size=1,stride=1,padding=0)\n",
    "            self.add2.weight=kernel_add_ini(n,m)\n",
    "        \n",
    "        n=int(n/2)\n",
    "        m=int(m/2)\n",
    "        if n>=2 and m>=2:\n",
    "            self.shift3=nn.Conv2d(n*m,n*m,kernel_size=3,stride=1,padding=1)\n",
    "            self.shift3.weight=kernel_shift_ini(n,m)\n",
    "            self.add3 = nn.Conv2d(n*m,int(n/2)*int(m/2),kernel_size=1,stride=1,padding=0)\n",
    "            self.add3.weight=kernel_add_ini(n,m)\n",
    "        \n",
    "        \n",
    "    def get_descripteur(self,img,using_cuda):\n",
    "        descripteur_img=self.Relu(self.conv1(img))\n",
    "        b,c,h,w=descripteur_img.shape\n",
    "        couche_constante=0.5*torch.ones([1,1,h,w])\n",
    "        if using_cuda:\n",
    "            couche_constante=couche_constante.cuda()\n",
    "        descripteur_img=torch.cat((descripteur_img,couche_constante),1)\n",
    "        descripteur_img_norm=descripteur_img/torch.norm(descripteur_img,dim=1)\n",
    "        return descripteur_img_norm\n",
    "    \n",
    "    def forward(self,img,frag,using_cuda):\n",
    "        psize=4\n",
    "        \n",
    "        descripteur_input1=self.get_descripteur(img,using_cuda)\n",
    "        descripteur_input2=self.get_descripteur(frag,using_cuda)\n",
    "        \n",
    "        b,c,h,w=frag.shape\n",
    "        n=int(h/psize)\n",
    "        m=int(w/psize)\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if i==0 and j==0:\n",
    "                    map_corre=F.conv2d(descripteur_input1,get_patch(descripteur_input2,psize,i,j),padding=2)\n",
    "                else:\n",
    "                    a=F.conv2d(descripteur_input1,get_patch(descripteur_input2,psize,i,j),padding=2)\n",
    "                    map_corre=torch.cat((map_corre,a),1)\n",
    "        #shift\n",
    "        map_corre=self.maxpooling(map_corre)\n",
    "        map_corre=self.shift1(map_corre)\n",
    "        map_corre=self.add1(map_corre)\n",
    "        \n",
    "        \n",
    "        n=int(n/2)\n",
    "        m=int(m/2)\n",
    "        if n>=2 and m>=2:\n",
    "            map_corre=self.maxpooling(map_corre)\n",
    "            map_corre=self.shift2(map_corre)\n",
    "            map_corre=self.add2(map_corre)\n",
    "        \n",
    "        \n",
    "        n=int(n/2)\n",
    "        m=int(m/2)\n",
    "        if n>=2 and m>=2:\n",
    "            map_corre=self.maxpooling(map_corre)\n",
    "            map_corre=self.shift3(map_corre)\n",
    "            map_corre=self.add3(map_corre)\n",
    "        \n",
    "        \n",
    "        b,c,h,w=map_corre.shape\n",
    "        map_corre=map_corre/(map_corre.max())\n",
    "        return map_corre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_net(net,img,frag,frag_size,using_cuda,rotation):\n",
    "    Img=Image.fromarray(frag)\n",
    "    frag=np.array(Img.rotate(rotation))\n",
    "    h,w,c=frag.shape\n",
    "    n=int(h/frag_size)\n",
    "    m=int(w/frag_size)\n",
    "    frag_list=[]\n",
    "    position_frag=[]\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            frag_32=frag[i*frag_size:(i+1)*frag_size,j*frag_size:(j+1)*frag_size]\n",
    "            if test_fragment32_32(frag_32,0.6):\n",
    "                frag_list.append(frag_32)\n",
    "                position_frag.append([i*frag_size+frag_size/2,j*frag_size+frag_size/2])\n",
    "    img_tensor=img2tensor(img)\n",
    "    \n",
    "    if using_cuda:\n",
    "        img_tensor=img_tensor.cuda()\n",
    "    \n",
    "    score_list=[]\n",
    "    coordonnee_list=[]\n",
    "    for i in range(len(frag_list)):\n",
    "        frag_tensor=img2tensor(frag_list[i])\n",
    "        if using_cuda:\n",
    "            frag_tensor=frag_tensor.cuda()\n",
    "        res=net.forward(img_tensor,frag_tensor,using_cuda)\n",
    "        if using_cuda:\n",
    "            res=res.cpu()\n",
    "        score,po_h,po_w=show_coordonnee(res)\n",
    "        coordonnee_list.append([po_h,po_w])\n",
    "        score_list.append(score)\n",
    "    h_img,w_img,c=img.shape\n",
    "    position=[]\n",
    "    for i in range(len(coordonnee_list)):\n",
    "        x0=position_frag[i][0]\n",
    "        y0=position_frag[i][1]\n",
    "        x1=int(round(h_img*coordonnee_list[i][0]))\n",
    "        y1=int(round(w_img*coordonnee_list[i][1]))\n",
    "        position.append([x0,y0,x1,y1])\n",
    "    return score_list,position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotate_patch(frag,frag_size,rotation):\n",
    "    Img_frag=Image.fromarray(frag)\n",
    "    frag_rotate=np.array(Img_frag.rotate(rotation))\n",
    "    patch,vt=get_training_fragment(frag_size,frag_rotate)\n",
    "    while test_fragment32_32(patch,0.9)==False:\n",
    "        patch,vt=get_training_fragment(frag_size,frag_rotate)\n",
    "    patch_rotate=patch\n",
    "    for i in range(20):\n",
    "        patch,vt=get_training_fragment(frag_size,frag_rotate)\n",
    "        while test_fragment32_32(patch,0.9)==False:\n",
    "            patch,vt=get_training_fragment(frag_size,frag_rotate)\n",
    "        patch_rotate=np.concatenate((patch_rotate,patch),axis=0)\n",
    "    return patch_rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouver_rotate(net,frag,img,frag_size,using_cuda):\n",
    "    rotation=[]\n",
    "    for i in range(18):\n",
    "        frag_rotate=get_rotate_patch(frag,frag_size,i*20)\n",
    "        score,position=run_net(net,img,frag_rotate,frag_size,using_cuda,0)\n",
    "        rotate=sum(score)/len(score)\n",
    "        rotation.append(rotate)\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_point(x,y):\n",
    "    p=np.zeros((3,1))\n",
    "    p[0][0]=x\n",
    "    p[1][0]=y\n",
    "    p[2][0]=1\n",
    "    return p\n",
    "\n",
    "def selectionner_points(n,M):\n",
    "    table=[]\n",
    "    for i in range(M):\n",
    "        table.append(i)\n",
    "    result=[]\n",
    "    for i in range(n):\n",
    "        index=random.randint(0,M-i)\n",
    "        result.append(table[index])\n",
    "        table[index]=table[M-1-i]\n",
    "    return result\n",
    "\n",
    "def position_rotation(h,centre_frag):\n",
    "    centre=h@centre_frag\n",
    "    cos_rot=(h[0][0]+h[1][1])/2\n",
    "    sin_rot=(h[1][0]-h[0][1])/2\n",
    "    tan_rot=sin_rot/(cos_rot+0.0000001)\n",
    "    if cos_rot>0:\n",
    "        rot_frag=math.atan(tan_rot)*(180/pi)\n",
    "    else:\n",
    "        rot_frag=math.atan(tan_rot)*(180/pi)+180\n",
    "    rot_frag=-rot_frag\n",
    "    if rot_frag>0:\n",
    "        rot_frag-=360\n",
    "    return centre[0][0],centre[1][0],rot_frag\n",
    "\n",
    "def test_frag(inline,frag,fres):\n",
    "    itera=10\n",
    "    frag_inline=[]\n",
    "    fres_inline=[]\n",
    "    for i in range(np.size(inline,0)):\n",
    "        if inline[i]==1:\n",
    "            frag_inline.append([frag[i][0],frag[i][1]])\n",
    "            fres_inline.append([fres[i][0],fres[i][1]])\n",
    "    p=[]\n",
    "    for i in range(itera):\n",
    "        point_test=selectionner_points(2,np.size(frag_inline,0))\n",
    "        diff_x_frag=frag_inline[point_test[1]][0]-frag_inline[point_test[0]][0]\n",
    "        diff_y_frag=frag_inline[point_test[1]][1]-frag_inline[point_test[0]][1]\n",
    "        diff_frag=sqrt(pow(diff_x_frag,2)+pow(diff_y_frag,2))\n",
    "        \n",
    "        diff_x_fres=fres_inline[point_test[1]][0]-fres_inline[point_test[0]][0]\n",
    "        diff_y_fres=fres_inline[point_test[1]][1]-fres_inline[point_test[0]][1]\n",
    "        diff_fres=sqrt(pow(diff_x_fres,2)+pow(diff_y_fres,2))\n",
    "        if diff_frag !=0:\n",
    "            fsf=diff_fres/diff_frag\n",
    "            p.append([fsf])\n",
    "        result=np.mean(p)\n",
    "    return result\n",
    "\n",
    "def frag_match(frag,img,position):\n",
    "    \n",
    "    frag_size=frag.shape\n",
    "    centre_frag=creer_point(frag_size[0]/2,frag_size[1]/2)\n",
    "    \n",
    "    retained_matches = []\n",
    "    frag=[]\n",
    "    fres=[]\n",
    "    for i in range(len(position)):\n",
    "        frag.append([float(position[i][0]),float(position[i][1])])\n",
    "        fres.append([float(position[i][2]),float(position[i][3])])\n",
    "    \n",
    "    if np.size(frag)>0:\n",
    "        h,inline=cv2.estimateAffinePartial2D(np.array(frag),np.array(fres))\n",
    "        if np.size(h)!=6:\n",
    "             return -1\n",
    "        else:\n",
    "            x,y,rot=position_rotation(h,centre_frag)\n",
    "            pourcenttage=sum(inline)/np.size(frag,0)\n",
    "            \n",
    "            if sum(inline)>3:\n",
    "                p=test_frag(inline,frag,fres)\n",
    "                if abs(p-1)<0.1:\n",
    "                    return(round(x),round(y),round(rot,3))\n",
    "                else:\n",
    "                    return -1\n",
    "    \n",
    "    else:\n",
    "        return -1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    frag_size=16\n",
    "    using_cuda=True\n",
    "    net=load_net(\"./Training_300_fresque0\")\n",
    "    img_test=cv2.imread(\"./fresque1.ppm\")\n",
    "    frag_test=cv2.imread(\"./frag_fresque1.png\")\n",
    "    Img_frag=Image.fromarray(frag_test)\n",
    "    frag_test=np.array(Img_frag.rotate(-50))\n",
    "    rot=trouver_rotate(net,frag_test,img_test,frag_size,using_cuda)\n",
    "    rotation=np.where(rot==min(rot))[0][0]*20\n",
    "    \n",
    "    score,position=run_net(net,img_test,frag_test,frag_size,using_cuda,rotation)\n",
    "    \n",
    "    frag_position=frag_match(frag_test,img_test,position)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398.0, 522.0, -350.178)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frag_position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
